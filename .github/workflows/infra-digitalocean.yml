name: DigitalOcean Kubernetes Infrastructure

on:
  workflow_dispatch:
    inputs:
      action:
        type: choice
        options: [ plan, apply, destroy ]
        default: plan
        description: "Ação do Terraform (plan/apply/destroy)"
      environment:
        type: choice
        options: [ dev, staging, prod ]
        default: dev
        description: "Ambiente para deploy"
      enable_managed_database:
        type: boolean
        default: true
        description: "Habilitar banco de dados gerenciado"
      deploy_k8s_manifests:
        type: boolean
        default: false
        description: "Deploy dos manifestos K8s após criar cluster"

env:
  TF_ROOT: infra

jobs:
  terraform:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    environment: ${{ github.event.inputs.environment || 'dev' }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.x


      - name: Validate DigitalOcean Token
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
        run: |
          test -n "$DIGITALOCEAN_TOKEN" || { echo "Missing DIGITALOCEAN_TOKEN secret"; exit 1; }
          echo "DigitalOcean token is present"

      - name: Generate SSH Key (if not exists)
        run: |
          if [ ! -f ~/.ssh/id_rsa ]; then
            ssh-keygen -t rsa -b 4096 -f ~/.ssh/id_rsa -N ""
            echo "Generated new SSH key"
          fi
          echo "SSH_PUBLIC_KEY<<EOF" >> $GITHUB_ENV
          cat ~/.ssh/id_rsa.pub >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV

      - name: Terraform Init (DigitalOcean Spaces Backend)
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.SPACES_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.SPACES_SECRET_KEY }}
        run: |
          terraform -chdir="$TF_ROOT" init -reconfigure \
            -backend-config="endpoint=https://nyc3.digitaloceanspaces.com" \
            -backend-config="bucket=fishing-map-${{ github.event.inputs.environment || 'dev' }}-terraform-state" \
            -backend-config="key=terraform.tfstate" \
            -backend-config="region=us-east-1"

      - name: Create terraform.tfvars
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
          SPACES_ACCESS_KEY: ${{ secrets.SPACES_ACCESS_KEY }}
          SPACES_SECRET_KEY: ${{ secrets.SPACES_SECRET_KEY }}
        run: |
          cat > $TF_ROOT/terraform.tfvars << EOF
          do_token = "$DIGITALOCEAN_TOKEN"
          spaces_access_key = "$SPACES_ACCESS_KEY"
          spaces_secret_key = "$SPACES_SECRET_KEY"
          project_name = "fishing-map"
          environment = "${{ github.event.inputs.environment || 'dev' }}"
          enable_managed_database = ${{ github.event.inputs.enable_managed_database || false }}
          domain_name = "${{ vars.DOMAIN_NAME || '' }}"
          EOF

      - name: Terraform Plan
        if: ${{ github.event.inputs.action == 'plan' }}
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.SPACES_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.SPACES_SECRET_KEY }}
        run: |
          terraform -chdir="$TF_ROOT" plan \
            -var-file="terraform.tfvars"

      - name: Terraform Apply
        if: ${{ github.event.inputs.action == 'apply' }}
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.SPACES_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.SPACES_SECRET_KEY }}
        run: |
          terraform -chdir="$TF_ROOT" apply -auto-approve \
            -var-file="terraform.tfvars"

      - name: Terraform Destroy
        if: ${{ github.event.inputs.action == 'destroy' }}
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          terraform -chdir="$TF_ROOT" destroy -auto-approve \
            -var-file="terraform.tfvars"

      - name: Show Outputs
        if: ${{ github.event.inputs.action == 'apply' }}
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.SPACES_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.SPACES_SECRET_KEY }}
        run: |
          echo "=== Kubernetes Cluster Information ==="
          terraform -chdir="$TF_ROOT" output -json > outputs.json
          
          echo "Cluster Name: $(terraform -chdir="$TF_ROOT" output -raw cluster_name)"
          echo "Cluster Region: $(terraform -chdir="$TF_ROOT" output -raw cluster_region)"
          echo "Cluster Version: $(terraform -chdir="$TF_ROOT" output -raw cluster_version)"
          echo "Registry Endpoint: $(terraform -chdir="$TF_ROOT" output -raw registry_endpoint)"
          echo ""
          echo "Kubeconfig Command: $(terraform -chdir="$TF_ROOT" output -raw kubeconfig_command)"

      - name: Install doctl and kubectl
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.deploy_k8s_manifests == 'true' }}
        run: |
          # Install doctl
          cd /tmp
          wget https://github.com/digitalocean/doctl/releases/download/v1.104.0/doctl-1.104.0-linux-amd64.tar.gz
          tar xf ./doctl-1.104.0-linux-amd64.tar.gz
          sudo mv ./doctl /usr/local/bin
          
          # Install kubectl
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

      - name: Setup Kubernetes Access
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.deploy_k8s_manifests == 'true' }}
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.SPACES_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.SPACES_SECRET_KEY }}
        run: |
          # Authenticate doctl
          doctl auth init --access-token $DIGITALOCEAN_TOKEN
          
          # Get cluster name and configure kubectl
          CLUSTER_NAME=$(terraform -chdir="$TF_ROOT" output -raw cluster_name)
          echo "Setting up kubectl for cluster: $CLUSTER_NAME"
          doctl kubernetes cluster kubeconfig save $CLUSTER_NAME
          
          # Verify connection
          kubectl get nodes
          kubectl get namespaces

      - name: Install Nginx Ingress Controller
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.deploy_k8s_manifests == 'true' }}
        run: |
          echo "Instalando Nginx Ingress Controller..."
          
          # Criar namespace do ingress-nginx
          kubectl create namespace ingress-nginx --dry-run=client -o yaml | kubectl apply -f -
          
          # Adicionar repo Helm
          helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
          helm repo update
          
          # Instalar ou atualizar Nginx Ingress usando values.yaml
          echo "Instalando Nginx Ingress com configuracoes customizadas..."
          helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
            --namespace ingress-nginx \
            --create-namespace \
            --values helm/nginx-ingress-values.yaml \
            --wait \
            --timeout 10m
          
          echo "Nginx Ingress Controller instalado"
          
          # Aguardar LoadBalancer IP
          echo "Aguardando LoadBalancer IP..."
          kubectl wait --for=condition=available --timeout=300s deployment/ingress-nginx-controller -n ingress-nginx
          
          # Aguardar servico ter IP externo
          echo "Aguardando IP externo do LoadBalancer..."
          for i in {1..30}; do
            LB_IP=$(kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null)
            if [ -n "$LB_IP" ]; then
              echo "LoadBalancer IP obtido: $LB_IP"
              break
            fi
            echo "Tentativa $i/30: Aguardando IP..."
            sleep 10
          done
          
          if [ -z "$LB_IP" ]; then
            echo "ERRO: Nao foi possivel obter IP do LoadBalancer"
            kubectl get svc ingress-nginx-controller -n ingress-nginx
            exit 1
          fi
          
          echo "NGINX_LB_IP=$LB_IP" >> $GITHUB_ENV
          
          # Verificar se Nginx esta respondendo
          echo "Testando Nginx Ingress..."
          kubectl run test-nginx --rm -i --restart=Never --image=curlimages/curl -- \
            curl -I http://ingress-nginx-controller.ingress-nginx.svc.cluster.local || echo "Teste ignorado"

      - name: Install cert-manager
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.deploy_k8s_manifests == 'true' }}
        run: |
          echo "Instalando cert-manager..."
          
          # Instalar cert-manager
          kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.3/cert-manager.yaml
          
          # Aguardar pods ficarem prontos
          kubectl wait --for=condition=available --timeout=300s deployment/cert-manager -n cert-manager
          kubectl wait --for=condition=available --timeout=300s deployment/cert-manager-webhook -n cert-manager
          kubectl wait --for=condition=available --timeout=300s deployment/cert-manager-cainjector -n cert-manager
          
          echo "cert-manager instalado"

      - name: Install ArgoCD
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.deploy_k8s_manifests == 'true' }}
        run: |
          echo "Instalando ArgoCD (GitOps)..."
          
          # Criar namespace
          kubectl create namespace argocd --dry-run=client -o yaml | kubectl apply -f -
          
          # Instalar ArgoCD
          kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
          
          # Aguardar pods ficarem prontos
          echo "Aguardando ArgoCD ficar pronto..."
          kubectl wait --for=condition=available --timeout=300s deployment/argocd-server -n argocd
          
          # Obter senha inicial do admin
          ARGOCD_PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)
          echo "ArgoCD Admin Password: $ARGOCD_PASSWORD"
          echo "ARGOCD_PASSWORD=$ARGOCD_PASSWORD" >> $GITHUB_ENV
          
          echo "ArgoCD instalado (ingress será configurado pelo Helm chart)"

      - name: Prepare Secrets from Terraform Outputs
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.deploy_k8s_manifests == 'true' }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.SPACES_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.SPACES_SECRET_KEY }}
        run: |
          echo "Extraindo valores do Terraform..."
          
          # Extrair outputs do Terraform
          cd $TF_ROOT
          DB_HOST=$(terraform output -raw database_host 2>/dev/null || echo "")
          DB_PORT=$(terraform output -raw database_port 2>/dev/null || echo "25060")
          DB_NAME=$(terraform output -raw database_name 2>/dev/null || echo "fishing_map")
          DB_USER=$(terraform output -raw database_user 2>/dev/null || echo "doadmin")
          DB_PASSWORD=$(terraform output -raw database_password 2>/dev/null || echo "")
          REGISTRY_ENDPOINT=$(terraform output -raw registry_endpoint)
          
          # Extrair Spaces outputs
          SPACES_ENDPOINT=$(terraform output -raw spaces_assets_bucket_endpoint 2>/dev/null || echo "")
          SPACES_BUCKET=$(terraform output -raw spaces_assets_bucket_name 2>/dev/null || echo "")
          SPACES_REGION=$(terraform output -raw spaces_assets_bucket_region 2>/dev/null || echo "nyc3")
          SPACES_CDN_URL=$(terraform output -raw spaces_assets_cdn_endpoint 2>/dev/null || echo "")
          
          # Exportar para próximos steps
          echo "DB_HOST=$DB_HOST" >> $GITHUB_ENV
          echo "DB_PORT=$DB_PORT" >> $GITHUB_ENV
          echo "DB_NAME=$DB_NAME" >> $GITHUB_ENV
          echo "DB_USER=$DB_USER" >> $GITHUB_ENV
          echo "DB_PASSWORD=$DB_PASSWORD" >> $GITHUB_ENV
          echo "REGISTRY_ENDPOINT=$REGISTRY_ENDPOINT" >> $GITHUB_ENV
          echo "SPACES_ENDPOINT=$SPACES_ENDPOINT" >> $GITHUB_ENV
          echo "SPACES_BUCKET=$SPACES_BUCKET" >> $GITHUB_ENV
          echo "SPACES_REGION=$SPACES_REGION" >> $GITHUB_ENV
          echo "SPACES_CDN_URL=$SPACES_CDN_URL" >> $GITHUB_ENV
          
          cd ..


      - name: Deploy Kubernetes Manifests
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.deploy_k8s_manifests == 'true' }}
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
          REDIS_PASSWORD: ${{ secrets.REDIS_PASSWORD }}
          JWT_SECRET: ${{ secrets.JWT_SECRET }}
          REFRESH_TOKEN_SECRET: ${{ secrets.REFRESH_TOKEN_SECRET }}
          API_KEY_WEATHER: ${{ secrets.API_KEY_WEATHER }}
          PGADMIN_PASSWORD: ${{ secrets.PGADMIN_PASSWORD }}
          SPACES_ACCESS_KEY: ${{ secrets.SPACES_ACCESS_KEY }}
          SPACES_SECRET_KEY: ${{ secrets.SPACES_SECRET_KEY }}
        run: |
          echo "FishingMap - Deploy via Helm"
          
          # Gerar senha do PgAdmin se não definida
          if [ -z "$PGADMIN_PASSWORD" ]; then
            PGADMIN_PASSWORD=$(openssl rand -base64 24)
            echo "PgAdmin password gerada automaticamente"
          fi
          
          # Criar namespace
          kubectl create namespace fishing-map --dry-run=client -o yaml | kubectl apply -f -
          
          # Criar registry secret
          echo "Configurando acesso ao container registry..."
          doctl registry login
          kubectl delete secret registry-secret -n fishing-map --ignore-not-found=true
          kubectl create secret docker-registry registry-secret \
            --docker-server=registry.digitalocean.com \
            --docker-username=$DIGITALOCEAN_TOKEN \
            --docker-password=$DIGITALOCEAN_TOKEN \
            -n fishing-map
          
          # Deploy Infrastructure via Helm
          echo "Deploying infrastructure via Helm..."
          helm upgrade --install fishing-map-infra ./helm \
            --namespace fishing-map \
            --set secrets.enabled=true \
            --set secrets.database.host="${DB_HOST}" \
            --set secrets.database.port="${DB_PORT}" \
            --set secrets.database.name="${DB_NAME}" \
            --set secrets.database.user="${DB_USER}" \
            --set secrets.database.password="${DB_PASSWORD}" \
            --set secrets.redis.password="${REDIS_PASSWORD}" \
            --set secrets.jwt.secret="${JWT_SECRET}" \
            --set secrets.jwt.refreshSecret="${REFRESH_TOKEN_SECRET}" \
            --set secrets.weather.apiKey="${API_KEY_WEATHER}" \
            --set secrets.spaces.accessKey="${SPACES_ACCESS_KEY}" \
            --set secrets.spaces.secretKey="${SPACES_SECRET_KEY}" \
            --set secrets.spaces.endpoint="${SPACES_ENDPOINT}" \
            --set secrets.spaces.bucket="${SPACES_BUCKET}" \
            --set secrets.spaces.region="${SPACES_REGION}" \
            --set secrets.spaces.cdnUrl="${SPACES_CDN_URL}" \
            --set redis.enabled=true \
            --set pgadmin.enabled=true \
            --set pgadmin.adminPassword="${PGADMIN_PASSWORD}" \
            --set pgadmin.database.host="${DB_HOST}" \
            --set pgadmin.database.port="${DB_PORT}" \
            --set pgadmin.database.user="${DB_USER}" \
            --set sonarqube.enabled=true \
            --set observability.enabled=true \
            --set ingress.devtools.enabled=true \
            --set ingress.api.enabled=true \
            --set argocd.enabled=true \
            --wait \
            --timeout 15m
          
          echo ""
          echo "Aguardando pods ficarem prontos..."
          
          # Verificar Redis
          if kubectl wait --for=condition=available --timeout=120s deployment/redis -n fishing-map 2>/dev/null; then
            echo "- Redis: PRONTO"
          else
            echo "- Redis: TIMEOUT (continuando...)"
          fi
          
          # Verificar Prometheus
          if kubectl wait --for=condition=available --timeout=120s deployment/prometheus -n fishing-map 2>/dev/null; then
            echo "- Prometheus: PRONTO"
          else
            echo "- Prometheus: TIMEOUT (continuando...)"
          fi
          
          # Verificar Grafana
          if kubectl wait --for=condition=available --timeout=120s deployment/grafana -n fishing-map 2>/dev/null; then
            echo "- Grafana: PRONTO"
          else
            echo "- Grafana: TIMEOUT (continuando...)"
          fi
          
          # Verificar Loki
          if kubectl wait --for=condition=available --timeout=120s deployment/loki -n fishing-map 2>/dev/null; then
            echo "- Loki: PRONTO"
          else
            echo "- Loki: TIMEOUT (continuando...)"
          fi
          
          # Verificar Jaeger
          if kubectl wait --for=condition=available --timeout=120s deployment/jaeger -n fishing-map 2>/dev/null; then
            echo "- Jaeger: PRONTO"
          else
            echo "- Jaeger: TIMEOUT (continuando...)"
          fi
          
          # Verificar SonarQube
          echo "Aguardando SonarQube (pode levar 5-10 minutos na primeira vez)..."
          if kubectl wait --for=condition=available --timeout=300s deployment/sonarqube -n fishing-map 2>/dev/null; then
            echo "- SonarQube: PRONTO"
          else
            echo "- SonarQube: Ainda inicializando (normal na primeira vez)"
          fi
          
          echo ""
          echo "Infraestrutura deployada via Helm!"
          echo ""
          echo "Helm release:"
          helm list -n fishing-map
          echo ""
          echo "Servicos deployados:"
          echo "  - Redis (Cache)"
          echo "  - Prometheus (Metricas)"
          echo "  - Grafana (Dashboards)"
          echo "  - Loki (Logs)"
          echo "  - Promtail (Log Collector)"
          echo "  - Jaeger (Tracing)"
          echo "  - SonarQube (Code Quality)"
          echo "  - PgAdmin (Database Admin)"
          echo ""
          echo "Nginx LoadBalancer IP: ${NGINX_LB_IP}"
          echo ""
          echo "Configure DNS:"
          echo "   A    api.fishingmap.com.br         ${NGINX_LB_IP}"
          echo "   A    grafana.fishingmap.com.br     ${NGINX_LB_IP}"
          echo "   A    prometheus.fishingmap.com.br  ${NGINX_LB_IP}"
          echo "   A    jaeger.fishingmap.com.br      ${NGINX_LB_IP}"
          echo "   A    sonar.fishingmap.com.br       ${NGINX_LB_IP}"
          echo "   A    pgadmin.fishingmap.com.br     ${NGINX_LB_IP}"
          echo "   A    argocd.fishingmap.com.br      ${NGINX_LB_IP}"
          echo ""
          echo "Credenciais:"
          echo "   Grafana: admin / admin"
          echo "   SonarQube: admin / admin"
          echo "   PgAdmin: admin@fishingmap.com.br / (ver secret pgadmin-secret)"
          echo "   ArgoCD: admin / ${ARGOCD_PASSWORD}"

      - name: Show Cluster Status
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.deploy_k8s_manifests == 'true' }}
        run: |
          echo "=== Cluster Status ==="
          kubectl get nodes -o wide
          
          echo ""
          echo "=== Pods Status ==="
          kubectl get pods -n fishing-map -o wide
          
          echo ""
          echo "=== Services Status ==="
          kubectl get svc -n fishing-map -o wide
          
          echo ""
          echo "=== Ingress Status ==="
          kubectl get ingress -n fishing-map -o wide
          
          echo ""
          echo "=== Ingress Details ==="
          kubectl describe ingress -n fishing-map
          
          echo ""
          echo "=== Nginx Ingress Controller Status ==="
          kubectl get pods -n ingress-nginx
          kubectl get svc -n ingress-nginx
          
          echo ""
          echo "=== Nginx Ingress Controller Logs (ultimas 50 linhas) ==="
          kubectl logs -n ingress-nginx deployment/ingress-nginx-controller --tail=50 || echo "Nao foi possivel obter logs"
          
          echo ""
          echo "=== Nginx LoadBalancer IP ==="
          kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.status.loadBalancer.ingress[0].ip}' || echo "Nginx LoadBalancer IP not ready yet"

      - name: Verify Infrastructure Status
        if: ${{ github.event.inputs.action == 'apply' }}
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
        run: |
          echo "=== Verificando Status da Infraestrutura ==="
          echo ""
          
          # Verificar se doctl está autenticado
          doctl auth init --access-token $DIGITALOCEAN_TOKEN
          
          # Listar clusters K8s
          echo "Clusters Kubernetes:"
          doctl kubernetes cluster list
          
          # Listar bancos de dados
          echo ""
          echo "Bancos de Dados:"
          doctl databases list
          
          # Listar container registries
          echo ""
          echo "Container Registries:"
          doctl registry list
          
          # Listar Spaces
          echo ""
          echo "Spaces (Object Storage):"
          doctl compute space list 2>/dev/null || echo "Nenhum Space listado (pode não ter permissão via doctl)"
          
          echo ""
          echo "Verificação completa!"

      - name: Next Steps
        if: ${{ github.event.inputs.action == 'apply' }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.SPACES_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.SPACES_SECRET_KEY }}
        run: |
          echo "=== Infraestrutura Criada com Sucesso! ==="
          echo ""
          echo "Próximos Passos:"
          echo ""
          
          # Capturar cluster name
          CLUSTER_NAME=$(terraform -chdir="$TF_ROOT" output -raw cluster_name 2>/dev/null || echo "fishing-map-${{ github.event.inputs.environment }}-cluster")
          
          echo "Configure kubectl localmente:"
          echo "   doctl auth init --access-token <your-token>"
          echo "   doctl kubernetes cluster kubeconfig save ${CLUSTER_NAME}"
          echo ""
          echo "Configure DNS para o LoadBalancer:"
          echo "   IP: ${NGINX_LB_IP}"
          echo "   Registros necessários: api.fishingmap.com.br, pgadmin.fishingmap.com.br, etc"
          echo ""
          echo "Execute a pipeline de Migrations:"
          echo "   Repositório: fishing-map/migrations"
          echo "   Actions → Build and Deploy Migrations → Run workflow"
          echo ""
          echo "Execute a pipeline de Backend:"
          echo "   Repositório: fishing-map/fishing-map-server"
          echo "   Actions → Build and Deploy Backend → Run workflow"
          echo ""
          echo "Atualize secrets com valores reais (JWT, API Keys):"
          echo "   kubectl edit secret app-secrets -n fishing-map"