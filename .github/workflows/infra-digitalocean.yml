name: DigitalOcean Kubernetes Infrastructure

on:
  workflow_dispatch:
    inputs:
      action:
        type: choice
        options: [ plan, apply, destroy ]
        default: plan
        description: "Ação do Terraform (plan/apply/destroy)"
      environment:
        type: choice
        options: [ dev, staging, prod ]
        default: dev
        description: "Ambiente para deploy"
      enable_managed_database:
        type: boolean
        default: true
        description: "Habilitar banco de dados gerenciado"
      deploy_k8s_manifests:
        type: boolean
        default: false
        description: "Deploy dos manifestos K8s após criar cluster"

env:
  TF_ROOT: infra

jobs:
  terraform:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    environment: ${{ github.event.inputs.environment || 'dev' }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.x


      - name: Validate DigitalOcean Token
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
        run: |
          test -n "$DIGITALOCEAN_TOKEN" || { echo "Missing DIGITALOCEAN_TOKEN secret"; exit 1; }
          echo "DigitalOcean token is present"

      - name: Generate SSH Key (if not exists)
        run: |
          if [ ! -f ~/.ssh/id_rsa ]; then
            ssh-keygen -t rsa -b 4096 -f ~/.ssh/id_rsa -N ""
            echo "Generated new SSH key"
          fi
          echo "SSH_PUBLIC_KEY<<EOF" >> $GITHUB_ENV
          cat ~/.ssh/id_rsa.pub >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV

      - name: Terraform Init (DigitalOcean Spaces Backend)
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.SPACES_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.SPACES_SECRET_KEY }}
        run: |
          terraform -chdir="$TF_ROOT" init -reconfigure \
            -backend-config="endpoint=https://nyc3.digitaloceanspaces.com" \
            -backend-config="bucket=fishing-map-${{ github.event.inputs.environment || 'dev' }}-terraform-state" \
            -backend-config="key=terraform.tfstate" \
            -backend-config="region=us-east-1"

      - name: Create terraform.tfvars
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
          SPACES_ACCESS_KEY: ${{ secrets.SPACES_ACCESS_KEY }}
          SPACES_SECRET_KEY: ${{ secrets.SPACES_SECRET_KEY }}
        run: |
          cat > $TF_ROOT/terraform.tfvars << EOF
          do_token = "$DIGITALOCEAN_TOKEN"
          spaces_access_key = "$SPACES_ACCESS_KEY"
          spaces_secret_key = "$SPACES_SECRET_KEY"
          project_name = "fishing-map"
          environment = "${{ github.event.inputs.environment || 'dev' }}"
          enable_managed_database = ${{ github.event.inputs.enable_managed_database || false }}
          domain_name = "${{ vars.DOMAIN_NAME || '' }}"
          EOF

      - name: Terraform Plan
        if: ${{ github.event.inputs.action == 'plan' }}
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.SPACES_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.SPACES_SECRET_KEY }}
        run: |
          terraform -chdir="$TF_ROOT" plan \
            -var-file="terraform.tfvars"

      - name: Terraform Apply
        if: ${{ github.event.inputs.action == 'apply' }}
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.SPACES_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.SPACES_SECRET_KEY }}
        run: |
          terraform -chdir="$TF_ROOT" apply -auto-approve \
            -var-file="terraform.tfvars"

      - name: Terraform Destroy
        if: ${{ github.event.inputs.action == 'destroy' }}
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          terraform -chdir="$TF_ROOT" destroy -auto-approve \
            -var-file="terraform.tfvars"

      - name: Show Outputs
        if: ${{ github.event.inputs.action == 'apply' }}
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.SPACES_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.SPACES_SECRET_KEY }}
        run: |
          echo "=== Kubernetes Cluster Information ==="
          terraform -chdir="$TF_ROOT" output -json > outputs.json
          
          echo "Cluster Name: $(terraform -chdir="$TF_ROOT" output -raw cluster_name)"
          echo "Cluster Region: $(terraform -chdir="$TF_ROOT" output -raw cluster_region)"
          echo "Cluster Version: $(terraform -chdir="$TF_ROOT" output -raw cluster_version)"
          echo "Registry Endpoint: $(terraform -chdir="$TF_ROOT" output -raw registry_endpoint)"
          echo ""
          echo "Kubeconfig Command: $(terraform -chdir="$TF_ROOT" output -raw kubeconfig_command)"

      - name: Install doctl and kubectl
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.deploy_k8s_manifests == 'true' }}
        run: |
          # Install doctl
          cd /tmp
          wget https://github.com/digitalocean/doctl/releases/download/v1.104.0/doctl-1.104.0-linux-amd64.tar.gz
          tar xf ./doctl-1.104.0-linux-amd64.tar.gz
          sudo mv ./doctl /usr/local/bin
          
          # Install kubectl
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

      - name: Setup Kubernetes Access
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.deploy_k8s_manifests == 'true' }}
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.SPACES_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.SPACES_SECRET_KEY }}
        run: |
          # Authenticate doctl
          doctl auth init --access-token $DIGITALOCEAN_TOKEN
          
          # Get cluster name and configure kubectl
          CLUSTER_NAME=$(terraform -chdir="$TF_ROOT" output -raw cluster_name)
          echo "Setting up kubectl for cluster: $CLUSTER_NAME"
          doctl kubernetes cluster kubeconfig save $CLUSTER_NAME
          
          # Verify connection
          kubectl get nodes
          kubectl get namespaces

      - name: Install Nginx Ingress Controller
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.deploy_k8s_manifests == 'true' }}
        run: |
          echo "Instalando Nginx Ingress Controller..."
          
          # Criar namespace do ingress-nginx
          kubectl create namespace ingress-nginx --dry-run=client -o yaml | kubectl apply -f -
          
          # Adicionar repo Helm
          helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
          helm repo update
          
          # Instalar ou atualizar Nginx Ingress usando values.yaml
          echo "Instalando Nginx Ingress com configuracoes customizadas..."
          helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
            --namespace ingress-nginx \
            --create-namespace \
            --values k8s/nginx-ingress-values.yaml \
            --wait \
            --timeout 10m
          
          echo "Nginx Ingress Controller instalado"
          
          # Aguardar LoadBalancer IP
          echo "Aguardando LoadBalancer IP..."
          kubectl wait --for=condition=available --timeout=300s deployment/ingress-nginx-controller -n ingress-nginx
          
          # Aguardar servico ter IP externo
          echo "Aguardando IP externo do LoadBalancer..."
          for i in {1..30}; do
            LB_IP=$(kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null)
            if [ -n "$LB_IP" ]; then
              echo "LoadBalancer IP obtido: $LB_IP"
              break
            fi
            echo "Tentativa $i/30: Aguardando IP..."
            sleep 10
          done
          
          if [ -z "$LB_IP" ]; then
            echo "ERRO: Nao foi possivel obter IP do LoadBalancer"
            kubectl get svc ingress-nginx-controller -n ingress-nginx
            exit 1
          fi
          
          echo "NGINX_LB_IP=$LB_IP" >> $GITHUB_ENV
          
          # Verificar se Nginx esta respondendo
          echo "Testando Nginx Ingress..."
          kubectl run test-nginx --rm -i --restart=Never --image=curlimages/curl -- \
            curl -I http://ingress-nginx-controller.ingress-nginx.svc.cluster.local || echo "Teste ignorado"

      - name: Install cert-manager
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.deploy_k8s_manifests == 'true' }}
        run: |
          echo "Instalando cert-manager..."
          
          # Instalar cert-manager
          kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.3/cert-manager.yaml
          
          # Aguardar pods ficarem prontos
          kubectl wait --for=condition=available --timeout=300s deployment/cert-manager -n cert-manager
          kubectl wait --for=condition=available --timeout=300s deployment/cert-manager-webhook -n cert-manager
          kubectl wait --for=condition=available --timeout=300s deployment/cert-manager-cainjector -n cert-manager
          
          echo "cert-manager instalado"

      - name: Install ArgoCD
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.deploy_k8s_manifests == 'true' }}
        run: |
          echo "Instalando ArgoCD (GitOps)..."
          
          # Criar namespace
          kubectl create namespace argocd --dry-run=client -o yaml | kubectl apply -f -
          
          # Instalar ArgoCD
          kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
          
          # Aguardar pods ficarem prontos
          echo "Aguardando ArgoCD ficar pronto..."
          kubectl wait --for=condition=available --timeout=300s deployment/argocd-server -n argocd
          
          # Configurar ingress do ArgoCD
          echo "Configurando ingress do ArgoCD..."
          kubectl apply -f k8s/argocd/ingress.yaml
          
          # Obter senha inicial do admin
          ARGOCD_PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)
          echo "ArgoCD Admin Password: $ARGOCD_PASSWORD"
          echo "ARGOCD_PASSWORD=$ARGOCD_PASSWORD" >> $GITHUB_ENV
          
          echo "ArgoCD instalado e ingress configurado"

      - name: Prepare Secrets from Terraform Outputs
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.deploy_k8s_manifests == 'true' }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.SPACES_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.SPACES_SECRET_KEY }}
        run: |
          echo "Extraindo valores do Terraform..."
          
          # Extrair outputs do Terraform
          cd $TF_ROOT
          DB_HOST=$(terraform output -raw database_host 2>/dev/null || echo "")
          DB_PORT=$(terraform output -raw database_port 2>/dev/null || echo "25060")
          DB_NAME=$(terraform output -raw database_name 2>/dev/null || echo "fishing_map")
          DB_USER=$(terraform output -raw database_user 2>/dev/null || echo "doadmin")
          DB_PASSWORD=$(terraform output -raw database_password 2>/dev/null || echo "")
          REGISTRY_ENDPOINT=$(terraform output -raw registry_endpoint)
          
          # Extrair Spaces outputs
          SPACES_ENDPOINT=$(terraform output -raw spaces_assets_bucket_endpoint 2>/dev/null || echo "")
          SPACES_BUCKET=$(terraform output -raw spaces_assets_bucket_name 2>/dev/null || echo "")
          SPACES_REGION=$(terraform output -raw spaces_assets_bucket_region 2>/dev/null || echo "nyc3")
          SPACES_CDN_URL=$(terraform output -raw spaces_assets_cdn_endpoint 2>/dev/null || echo "")
          
          # Exportar para próximos steps
          echo "DB_HOST=$DB_HOST" >> $GITHUB_ENV
          echo "DB_PORT=$DB_PORT" >> $GITHUB_ENV
          echo "DB_NAME=$DB_NAME" >> $GITHUB_ENV
          echo "DB_USER=$DB_USER" >> $GITHUB_ENV
          echo "DB_PASSWORD=$DB_PASSWORD" >> $GITHUB_ENV
          echo "REGISTRY_ENDPOINT=$REGISTRY_ENDPOINT" >> $GITHUB_ENV
          echo "SPACES_ENDPOINT=$SPACES_ENDPOINT" >> $GITHUB_ENV
          echo "SPACES_BUCKET=$SPACES_BUCKET" >> $GITHUB_ENV
          echo "SPACES_REGION=$SPACES_REGION" >> $GITHUB_ENV
          echo "SPACES_CDN_URL=$SPACES_CDN_URL" >> $GITHUB_ENV
          
          cd ..


      - name: Deploy Kubernetes Manifests
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.deploy_k8s_manifests == 'true' }}
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
          REDIS_PASSWORD: ${{ secrets.REDIS_PASSWORD }}
          AWS_ACCESS_KEY_ID: ${{ secrets.SPACES_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.SPACES_SECRET_KEY }}
        run: |
          echo "FishingMap - Deploy Automatizado no Kubernetes"
          
          # 1. Atualizar registry endpoint nos manifestos
          echo "[1/10] Atualizando registry endpoint..."
          find k8s/ -name "*.yaml" -exec sed -i "s|registry.digitalocean.com/fishing-map|${REGISTRY_ENDPOINT}|g" {} \;
          
          # 2. Preencher secrets automaticamente
          echo "[2/7] Preenchendo secrets com valores do Terraform e GitHub Secrets..."
          sed -i "s|__DB_HOST__|${DB_HOST}|g" k8s/secrets.yaml
          sed -i "s|__DB_PORT__|${DB_PORT}|g" k8s/secrets.yaml
          sed -i "s|__DB_NAME__|${DB_NAME}|g" k8s/secrets.yaml
          sed -i "s|__DB_USER__|${DB_USER}|g" k8s/secrets.yaml
          sed -i "s|__DB_PASSWORD__|${DB_PASSWORD}|g" k8s/secrets.yaml
          sed -i "s|__REDIS_PASSWORD__|${REDIS_PASSWORD}|g" k8s/secrets.yaml
          sed -i "s|__SPACES_ACCESS_KEY__|${SPACES_ACCESS_KEY}|g" k8s/secrets.yaml
          sed -i "s|__SPACES_SECRET_KEY__|${SPACES_SECRET_KEY}|g" k8s/secrets.yaml
          
          # JWT e API_KEY serão configurados depois via kubectl ou pipeline da aplicação
          sed -i "s|__JWT_SECRET__|CHANGE_ME_LATER|g" k8s/secrets.yaml
          sed -i "s|__REFRESH_TOKEN_SECRET__|CHANGE_ME_LATER|g" k8s/secrets.yaml
          sed -i "s|__API_KEY_WEATHER__|CHANGE_ME_LATER|g" k8s/secrets.yaml
          
          # Preencher ConfigMap com Spaces
          sed -i "s|__SPACES_ENDPOINT__|${SPACES_ENDPOINT}|g" k8s/configmap.yaml
          sed -i "s|__SPACES_BUCKET__|${SPACES_BUCKET}|g" k8s/configmap.yaml
          sed -i "s|__SPACES_REGION__|${SPACES_REGION}|g" k8s/configmap.yaml
          sed -i "s|__SPACES_CDN_URL__|${SPACES_CDN_URL}|g" k8s/configmap.yaml
          
          # Preencher PgAdmin com credenciais do banco (para manutenção em produção)
          echo "[2.1/10] Configurando PgAdmin com credenciais do banco..."
          sed -i "s|__DB_HOST__|${DB_HOST}|g" k8s/pgadmin-deployment.yaml
          sed -i "s|__DB_PORT__|${DB_PORT}|g" k8s/pgadmin-deployment.yaml
          sed -i "s|__DB_USER__|${DB_USER}|g" k8s/pgadmin-deployment.yaml
          sed -i "s|__DB_PASSWORD__|${DB_PASSWORD}|g" k8s/pgadmin-deployment.yaml
          # Gera senha aleatória para PgAdmin (pode ser recuperada via kubectl get secret)
          PGADMIN_PASSWORD=$(openssl rand -base64 24)
          sed -i "s|__PGADMIN_PASSWORD__|${PGADMIN_PASSWORD}|g" k8s/pgadmin-deployment.yaml
          echo "PgAdmin configurado (senha admin salva no secret)"
          
          # 3. Criar registry secret
          echo "[3/10] Configurando acesso ao container registry..."
          doctl registry login
          kubectl create secret docker-registry registry-secret \
            --from-file=.dockerconfigjson=$HOME/.docker/config.json \
            --namespace=fishing-map \
            --dry-run=client -o yaml | kubectl apply -f - || true
          
          # 4. Aplicar namespace
          echo "[4/10] Criando namespace..."
          kubectl apply -f k8s/namespace.yaml
          
          # 5. Aplicar secrets e configs
          echo "[5/10] Aplicando secrets e configurações..."
          kubectl apply -f k8s/secrets.yaml
          kubectl apply -f k8s/configmap.yaml
          
          # 6. Deploy Redis
          echo "[6/8] Deployando Redis..."
          kubectl apply -f k8s/redis-deployment.yaml
          kubectl wait --for=condition=available --timeout=300s deployment/redis -n fishing-map
          
          # 7. Deploy Stack de Observabilidade (Grafana, Prometheus, Loki, Jaeger)
          echo "[7/10] Deployando stack de observabilidade..."
          kubectl apply -f k8s/observability/configmaps.yaml
          kubectl apply -f k8s/observability/stack-simple.yaml
          
          echo "Aguardando pods de observabilidade ficarem prontos (timeout: 2 min cada)..."
          
          # Prometheus
          if kubectl wait --for=condition=available --timeout=120s deployment/prometheus -n fishing-map 2>/dev/null; then
            echo "- Prometheus: PRONTO"
          else
            echo "- Prometheus: TIMEOUT (continuando...)"
            kubectl get pods -n fishing-map -l app=prometheus
            kubectl describe pod -n fishing-map -l app=prometheus | tail -20
          fi
          
          # Grafana
          if kubectl wait --for=condition=available --timeout=120s deployment/grafana -n fishing-map 2>/dev/null; then
            echo "- Grafana: PRONTO"
          else
            echo "- Grafana: TIMEOUT (continuando...)"
            kubectl get pods -n fishing-map -l app=grafana
          fi
          
          # Loki
          if kubectl wait --for=condition=available --timeout=120s deployment/loki -n fishing-map 2>/dev/null; then
            echo "- Loki: PRONTO"
          else
            echo "- Loki: TIMEOUT (continuando...)"
            kubectl get pods -n fishing-map -l app=loki
          fi
          
          # Jaeger
          if kubectl wait --for=condition=available --timeout=120s deployment/jaeger -n fishing-map 2>/dev/null; then
            echo "- Jaeger: PRONTO"
          else
            echo "- Jaeger: TIMEOUT (continuando...)"
            kubectl get pods -n fishing-map -l app=jaeger
          fi
          
          echo ""
          echo "Status geral dos pods de observabilidade:"
          kubectl get pods -n fishing-map | grep -E "prometheus|grafana|loki|jaeger" || true
          echo ""
          echo "NOTA: Pods podem continuar inicializando em background"
          echo "Stack de observabilidade deployada (podem ainda estar inicializando)"
          echo ""
          
          # 8. Deploy DevTools (SonarQube)
          echo "[8/10] Deployando DevTools (SonarQube)..."

          kubectl apply -f k8s/devtools/sonarqube.yaml
          
          echo "Aguardando SonarQube PostgreSQL..."
          if kubectl wait --for=condition=available --timeout=120s deployment/sonarqube-postgres -n fishing-map 2>/dev/null; then
            echo "- SonarQube PostgreSQL: PRONTO"
          else
            echo "- SonarQube PostgreSQL: TIMEOUT (verificando...)"
            kubectl get pods -n fishing-map -l app=sonarqube-postgres
          fi
          
          echo "Aguardando SonarQube (isso pode levar 5-10 minutos)..."
          if kubectl wait --for=condition=available --timeout=180s deployment/sonarqube -n fishing-map 2>/dev/null; then
            echo "- SonarQube: PRONTO"
          else
            echo "- SonarQube: Ainda inicializando (normal na primeira vez)"
            kubectl get pods -n fishing-map -l app=sonarqube
            echo "NOTA: SonarQube continuara inicializando em background"
          fi
          echo ""
          
          # 10. Aplicar ClusterIssuer do cert-manager PRIMEIRO
          echo "[10/11] Configurando cert-manager ClusterIssuer..."
          kubectl apply -f k8s/cert-manager-issuer.yaml
          
          echo "Aguardando ClusterIssuer ficar pronto..."
          sleep 5
          kubectl get clusterissuer -o wide
          
          # 11. Deploy Ingress (rotas dos dominios) - DEPOIS dos pods estarem prontos
          echo "[11/11] Configurando Ingress..."
          kubectl apply -f k8s/devtools/ingress.yaml
          
          echo "Aguardando ingress ser criado..."
          sleep 5
          kubectl get ingress -n fishing-map
          
          echo "Aguardando certificados SSL serem emitidos (pode levar 2-3 minutos)..."
          for i in {1..12}; do
            CERT_STATUS=$(kubectl get certificate -n fishing-map devtools-fishingmap-tls -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "")
            if [ "$CERT_STATUS" == "True" ]; then
              echo "Certificado emitido com sucesso!"
              break
            fi
            echo "Tentativa $i/12: Certificado ainda nao emitido..."
            sleep 15
          done
          
          echo ""
          echo "Status dos certificados:"
          kubectl get certificate -n fishing-map -o wide || echo "Nenhum certificado encontrado"
          kubectl describe certificate -n fishing-map devtools-fishingmap-tls || echo "Certificado nao encontrado"
          
          echo ""
          echo "Ingress DevTools configurado para: grafana, prometheus, jaeger, sonarqube"
          echo "Ingress ArgoCD configurado separadamente (namespace argocd)"
          echo ""
          echo "Infraestrutura base criada com sucesso!"
          echo ""
          echo "Servicos deployados:"
          echo "  - Redis (Cache)"
          echo "  - Prometheus (Metricas)"
          echo "  - Grafana (Dashboards)"
          echo "  - Loki (Logs)"
          echo "  - Promtail (Log Collector)"
          echo "  - Jaeger (Tracing)"
          echo "  - SonarQube (Code Quality)"
          echo "  - ArgoCD (GitOps)"
          echo "  - Ingress Controller (Nginx)"
          echo "  - cert-manager (SSL)"
          echo ""
          
          # Aguardar certificado ser emitido
          echo "Aguardando certificados SSL (cert-manager)..."
          sleep 15
          kubectl get certificate -n fishing-map || true
          
          echo ""
          echo "Deploy completo!"
          echo ""
          echo "Nginx LoadBalancer IP: ${NGINX_LB_IP}"
          echo ""
          echo "Configure DNS (ou aguarde propagacao se ja configurou):"
          echo "   A    fishingmap.com.br             ${NGINX_LB_IP}"
          echo "   A    www.fishingmap.com.br         ${NGINX_LB_IP}"
          echo "   A    api.fishingmap.com.br         ${NGINX_LB_IP}"
          echo "   A    app.fishingmap.com.br         ${NGINX_LB_IP}"
          echo ""
          echo "Observability & DevTools:"
          echo "   A    grafana.fishingmap.com.br     ${NGINX_LB_IP}"
          echo "   A    prometheus.fishingmap.com.br  ${NGINX_LB_IP}"
          echo "   A    jaeger.fishingmap.com.br      ${NGINX_LB_IP}"
          echo "   A    sonarqube.fishingmap.com.br   ${NGINX_LB_IP}"
          echo "   A    argocd.fishingmap.com.br      ${NGINX_LB_IP}"
          echo ""
          echo "Credenciais de Acesso:"
          echo ""
          echo "Observability Stack:"
          echo "   Grafana: https://grafana.fishingmap.com.br"
          echo "      User: admin"
          echo "      Password: admin (altere apos primeiro login)"
          echo ""
          echo "   Prometheus: https://prometheus.fishingmap.com.br"
          echo "      (Sem autenticacao - use apenas para debug)"
          echo ""
          echo "   Jaeger: https://jaeger.fishingmap.com.br"
          echo "      (Sem autenticacao)"
          echo ""
          echo "DevTools:"
          echo "   SonarQube: https://sonarqube.fishingmap.com.br"
          echo "      User: admin"
          echo "      Password: admin (altere apos primeiro login)"
          echo "      AVISO: Primeira inicializacao pode levar 5-10 minutos"
          echo ""
          echo "   ArgoCD: https://argocd.fishingmap.com.br"
          echo "      User: admin"
          echo "      Password: ${ARGOCD_PASSWORD}"
          echo ""
          echo "Apos configurar o DNS, acesse: https://api.fishingmap.com.br/health"

      - name: Show Cluster Status
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.deploy_k8s_manifests == 'true' }}
        run: |
          echo "=== Cluster Status ==="
          kubectl get nodes -o wide
          
          echo ""
          echo "=== Pods Status ==="
          kubectl get pods -n fishing-map -o wide
          
          echo ""
          echo "=== Services Status ==="
          kubectl get svc -n fishing-map -o wide
          
          echo ""
          echo "=== Ingress Status ==="
          kubectl get ingress -n fishing-map -o wide
          
          echo ""
          echo "=== Ingress Details ==="
          kubectl describe ingress -n fishing-map
          
          echo ""
          echo "=== Nginx Ingress Controller Status ==="
          kubectl get pods -n ingress-nginx
          kubectl get svc -n ingress-nginx
          
          echo ""
          echo "=== Nginx Ingress Controller Logs (ultimas 50 linhas) ==="
          kubectl logs -n ingress-nginx deployment/ingress-nginx-controller --tail=50 || echo "Nao foi possivel obter logs"
          
          echo ""
          echo "=== Nginx LoadBalancer IP ==="
          kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.status.loadBalancer.ingress[0].ip}' || echo "Nginx LoadBalancer IP not ready yet"

      - name: Verify Infrastructure Status
        if: ${{ github.event.inputs.action == 'apply' }}
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
        run: |
          echo "=== Verificando Status da Infraestrutura ==="
          echo ""
          
          # Verificar se doctl está autenticado
          doctl auth init --access-token $DIGITALOCEAN_TOKEN
          
          # Listar clusters K8s
          echo "Clusters Kubernetes:"
          doctl kubernetes cluster list
          
          # Listar bancos de dados
          echo ""
          echo "Bancos de Dados:"
          doctl databases list
          
          # Listar container registries
          echo ""
          echo "Container Registries:"
          doctl registry list
          
          # Listar Spaces
          echo ""
          echo "Spaces (Object Storage):"
          doctl compute space list 2>/dev/null || echo "Nenhum Space listado (pode não ter permissão via doctl)"
          
          echo ""
          echo "Verificação completa!"

      - name: Next Steps
        if: ${{ github.event.inputs.action == 'apply' }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.SPACES_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.SPACES_SECRET_KEY }}
        run: |
          echo "=== Infraestrutura Criada com Sucesso! ==="
          echo ""
          echo "Próximos Passos:"
          echo ""
          
          # Capturar cluster name
          CLUSTER_NAME=$(terraform -chdir="$TF_ROOT" output -raw cluster_name 2>/dev/null || echo "fishing-map-${{ github.event.inputs.environment }}-cluster")
          
          echo "Configure kubectl localmente:"
          echo "   doctl auth init --access-token <your-token>"
          echo "   doctl kubernetes cluster kubeconfig save ${CLUSTER_NAME}"
          echo ""
          echo "Configure DNS para o LoadBalancer:"
          echo "   IP: ${NGINX_LB_IP}"
          echo "   Registros necessários: api.fishingmap.com.br, pgadmin.fishingmap.com.br, etc"
          echo ""
          echo "Execute a pipeline de Migrations:"
          echo "   Repositório: fishing-map/migrations"
          echo "   Actions → Build and Deploy Migrations → Run workflow"
          echo ""
          echo "Execute a pipeline de Backend:"
          echo "   Repositório: fishing-map/fishing-map-server"
          echo "   Actions → Build and Deploy Backend → Run workflow"
          echo ""
          echo "Atualize secrets com valores reais (JWT, API Keys):"
          echo "   kubectl edit secret app-secrets -n fishing-map"